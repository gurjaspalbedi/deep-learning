{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"hw4_tr7.pkl\",'rb')\n",
    "train_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"hw4_te7.pkl\",'rb')\n",
    "test_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6265, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 200\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref : https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.encode_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, kernel_size=2, stride=1),\n",
    "                nn.ReLU(),       \n",
    "                nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "\n",
    "\n",
    "        self.encode_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(8,16, kernel_size=2, stride=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=1))\n",
    "        \n",
    "        \n",
    "        self.encode_conv3 = nn.Sequential(\n",
    "                nn.Conv2d(16,32, kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        self.encode_conv4 = nn.Sequential(\n",
    "                nn.Conv2d(32,64, kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "        self.fc2 = nn.Linear(64, 5)\n",
    "        self.decode_start = nn.Linear(5, 64)\n",
    "        \n",
    "        self.decode_conv4 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(64,32, kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxUnpool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.decode_conv3 = nn.Sequential(\n",
    "                nn.Conv2d(32,16, kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxUnpool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.decode_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(16,8, kernel_size=2, stride=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxUnpool2d(kernel_size=2, stride=1))\n",
    "        \n",
    "        self.decode_conv1 = nn.Sequential(\n",
    "                nn.Conv2d(8, 1, kernel_size=2, stride=1),\n",
    "                nn.ReLU(),       \n",
    "                nn.MaxUnpool2d(kernel_size=2, stride=1))\n",
    "        \n",
    "#         self.fc1 = nn.Linear(in_features=int(16256), out_features=513)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        out = x[:,np.newaxis,:,:]\n",
    "        out = self.encode_conv1(out)\n",
    "        out = self.encode_conv2(out)\n",
    "        out = self.encode_conv3(out)\n",
    "        out = self.encode_conv4(out)\n",
    "        out  = out.view(200,-1)\n",
    "        return self.fc1(out), self.fc2(out)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        print('decod shape')\n",
    "        print(z.shape)\n",
    "        out = self.decode_start(z)\n",
    "        print('shape')\n",
    "        print(z.shape)\n",
    "#         out = z[:,np.newaxis,:,:]\n",
    "        out = self.decode_conv4(z)\n",
    "        out = self.decode_conv3(out)\n",
    "        out = self.decode_conv2(out)\n",
    "        out = self.decode_conv1(out)\n",
    "#         print(out.shape)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader),\n",
    "#                 loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decod shape\n",
      "torch.Size([200, 5])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNet' object has no attribute 'decode_starts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-143b4e3f1ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-141-c9440ef5eb87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mrecon_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-90cf00bcbce8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-138-90cf00bcbce8>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decod shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_starts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 535\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNet' object has no attribute 'decode_starts'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 400])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['fc22.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cb173cf2e8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.tensor([0.5,0.5,0.5,0.5,0.5]).cuda()\n",
    "ans = model.decode(z)\n",
    "ans = ans.reshape((28,28))\n",
    "plt.imshow(ans.cpu().detach().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data.cuda()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(1, 10):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, 20).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/sample_' + str(epoch) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
