{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import librosa\n",
    "import random\n",
    "from random import shuffle\n",
    "import codecs\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets.mnist\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Git\\Deep Learning\\Assignment4\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"hw4_trs.pkl\",'rb')\n",
    "train_data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"hw4_tes.pkl\",'rb')\n",
    "test_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape\n",
    "training = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "for sig in range(500):\n",
    "    stft = librosa.stft(train_data[sig], n_fft=1024, hop_length=512)\n",
    "#     stft.resize((513,32))\n",
    "    training.append(np.abs(stft).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 513)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 22631)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00127268, -0.00018181,  0.00027272, ..., -0.00363621,\n",
       "        -0.0034544 , -0.00418165],\n",
       "       [-0.00023365,  0.00023365,  0.        , ..., -0.00700938,\n",
       "        -0.00763243, -0.00957948],\n",
       "       [ 0.0014514 , -0.00019352,  0.00029028, ..., -0.00232224,\n",
       "        -0.00299957, -0.00261252],\n",
       "       ...,\n",
       "       [ 0.00022017,  0.00036695,  0.00014678, ...,  0.02803493,\n",
       "         0.01812729,  0.00910034],\n",
       "       [ 0.00011644,  0.00034932,  0.00034932, ..., -0.06386784,\n",
       "        -0.08779645, -0.10881403],\n",
       "       [ 0.00034393,  0.00080251,  0.00074519, ..., -0.00045858,\n",
       "        -0.00424185, -0.00492971]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = []\n",
    "for sig2 in range(200):\n",
    "    stft = librosa.stft(test_data[sig2], n_fft=1024, hop_length=512)\n",
    "#     print(stft.shape)\n",
    "#     stft.resize((513,45))\n",
    "    training.append(np.abs(stft).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(np.arange(3,10), np.arange(11,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 16180)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:9,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "positive_list = []\n",
    "negative_list = []\n",
    "m = [1,2,3]\n",
    "print(shuffle(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(number_of_speakers):\n",
    "    positive_pairs = np.zeros((number_of_speakers,9,2))\n",
    "    negative_pairs = np.zeros((number_of_speakers,9,2))\n",
    "    person = np.zeros((number_of_speakers,9))\n",
    "    for i in range(number_of_speakers):\n",
    "#         print(i)\n",
    "        complete_set = set(range(number_of_speakers * 10))\n",
    "        positive_set = set(range(i, i+10))\n",
    "        negative_set = set(complete_set - positive_set)\n",
    "\n",
    "        # print(list(positive_set))\n",
    "        positive_list = list(positive_set)\n",
    "        # print(len(positive_list))\n",
    "        negative_list = list(negative_set)\n",
    "#         print(positive_list)\n",
    "#         print(negative_list)\n",
    "#         shuffle(positive_list)\n",
    "#         shuffle(negative_list)\n",
    "\n",
    "        positive_combinations = np.array(random.sample(list(itertools.combinations(positive_list, 2)), 9) )\n",
    "        negative_combinations = np.array(random.sample(list(itertools.product(positive_list, negative_list)), 9))\n",
    "#         print(positive_combinations)\n",
    "#         print(negative_combinations)\n",
    "        positive_pairs[i] = positive_combinations\n",
    "        negative_pairs[i] = negative_combinations\n",
    "        person[i] = i\n",
    "    return positive_pairs, negative_pairs, person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs, negative_pairs, person = get_pairs(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.  9.]\n",
      "  [ 0.  2.]\n",
      "  [ 0.  6.]\n",
      "  [ 2.  5.]\n",
      "  [ 5.  6.]\n",
      "  [ 1.  2.]\n",
      "  [ 4.  6.]\n",
      "  [ 2.  6.]\n",
      "  [ 3.  5.]]\n",
      "\n",
      " [[ 1.  5.]\n",
      "  [ 4.  7.]\n",
      "  [ 7.  9.]\n",
      "  [ 3.  4.]\n",
      "  [ 9. 10.]\n",
      "  [ 2.  9.]\n",
      "  [ 5.  6.]\n",
      "  [ 4.  8.]\n",
      "  [ 7.  8.]]\n",
      "\n",
      " [[ 7. 11.]\n",
      "  [ 3.  8.]\n",
      "  [ 3.  5.]\n",
      "  [ 9. 11.]\n",
      "  [ 2.  3.]\n",
      "  [ 3.  9.]\n",
      "  [ 5.  7.]\n",
      "  [ 2.  8.]\n",
      "  [ 2.  6.]]\n",
      "\n",
      " [[ 7.  9.]\n",
      "  [ 4. 10.]\n",
      "  [ 5. 11.]\n",
      "  [ 6. 12.]\n",
      "  [ 7. 11.]\n",
      "  [ 4.  8.]\n",
      "  [ 3.  7.]\n",
      "  [ 5. 12.]\n",
      "  [ 4.  7.]]\n",
      "\n",
      " [[ 7. 11.]\n",
      "  [ 7. 10.]\n",
      "  [ 5.  8.]\n",
      "  [ 5. 12.]\n",
      "  [ 6.  9.]\n",
      "  [ 6. 10.]\n",
      "  [ 8. 10.]\n",
      "  [ 7. 12.]\n",
      "  [11. 13.]]\n",
      "\n",
      " [[ 9. 10.]\n",
      "  [ 9. 14.]\n",
      "  [12. 13.]\n",
      "  [ 8.  9.]\n",
      "  [ 8. 10.]\n",
      "  [ 9. 12.]\n",
      "  [12. 14.]\n",
      "  [ 8. 11.]\n",
      "  [ 5. 10.]]\n",
      "\n",
      " [[ 9. 11.]\n",
      "  [ 7. 14.]\n",
      "  [ 8. 12.]\n",
      "  [ 8. 13.]\n",
      "  [ 9. 10.]\n",
      "  [12. 15.]\n",
      "  [ 6. 11.]\n",
      "  [ 7. 10.]\n",
      "  [ 6.  8.]]\n",
      "\n",
      " [[ 8. 11.]\n",
      "  [ 9. 12.]\n",
      "  [10. 14.]\n",
      "  [13. 15.]\n",
      "  [11. 14.]\n",
      "  [ 7. 14.]\n",
      "  [12. 14.]\n",
      "  [ 7. 12.]\n",
      "  [ 9. 10.]]\n",
      "\n",
      " [[ 9. 15.]\n",
      "  [ 8. 17.]\n",
      "  [ 9. 10.]\n",
      "  [ 9. 16.]\n",
      "  [11. 12.]\n",
      "  [10. 17.]\n",
      "  [13. 15.]\n",
      "  [11. 14.]\n",
      "  [13. 16.]]\n",
      "\n",
      " [[12. 17.]\n",
      "  [ 9. 15.]\n",
      "  [13. 15.]\n",
      "  [15. 17.]\n",
      "  [13. 16.]\n",
      "  [14. 18.]\n",
      "  [ 9. 14.]\n",
      "  [14. 17.]\n",
      "  [11. 14.]]\n",
      "\n",
      " [[10. 18.]\n",
      "  [13. 18.]\n",
      "  [13. 16.]\n",
      "  [12. 15.]\n",
      "  [15. 17.]\n",
      "  [17. 19.]\n",
      "  [15. 19.]\n",
      "  [12. 13.]\n",
      "  [11. 12.]]\n",
      "\n",
      " [[15. 18.]\n",
      "  [13. 14.]\n",
      "  [13. 15.]\n",
      "  [11. 14.]\n",
      "  [17. 19.]\n",
      "  [14. 16.]\n",
      "  [14. 17.]\n",
      "  [12. 14.]\n",
      "  [12. 16.]]\n",
      "\n",
      " [[13. 14.]\n",
      "  [12. 16.]\n",
      "  [15. 17.]\n",
      "  [13. 21.]\n",
      "  [12. 13.]\n",
      "  [15. 21.]\n",
      "  [12. 19.]\n",
      "  [13. 18.]\n",
      "  [15. 16.]]\n",
      "\n",
      " [[19. 22.]\n",
      "  [13. 22.]\n",
      "  [21. 22.]\n",
      "  [16. 17.]\n",
      "  [14. 15.]\n",
      "  [15. 20.]\n",
      "  [18. 21.]\n",
      "  [13. 20.]\n",
      "  [13. 21.]]\n",
      "\n",
      " [[17. 23.]\n",
      "  [22. 23.]\n",
      "  [18. 22.]\n",
      "  [18. 23.]\n",
      "  [14. 17.]\n",
      "  [17. 21.]\n",
      "  [15. 19.]\n",
      "  [14. 21.]\n",
      "  [20. 22.]]\n",
      "\n",
      " [[17. 19.]\n",
      "  [21. 24.]\n",
      "  [16. 17.]\n",
      "  [20. 22.]\n",
      "  [15. 22.]\n",
      "  [20. 23.]\n",
      "  [16. 20.]\n",
      "  [19. 21.]\n",
      "  [18. 21.]]\n",
      "\n",
      " [[24. 25.]\n",
      "  [18. 20.]\n",
      "  [16. 17.]\n",
      "  [22. 23.]\n",
      "  [16. 20.]\n",
      "  [16. 22.]\n",
      "  [21. 22.]\n",
      "  [16. 25.]\n",
      "  [17. 22.]]\n",
      "\n",
      " [[17. 24.]\n",
      "  [22. 23.]\n",
      "  [18. 25.]\n",
      "  [18. 19.]\n",
      "  [21. 25.]\n",
      "  [19. 20.]\n",
      "  [20. 26.]\n",
      "  [23. 25.]\n",
      "  [19. 21.]]\n",
      "\n",
      " [[24. 27.]\n",
      "  [22. 27.]\n",
      "  [21. 24.]\n",
      "  [21. 27.]\n",
      "  [22. 26.]\n",
      "  [24. 25.]\n",
      "  [23. 26.]\n",
      "  [19. 24.]\n",
      "  [18. 25.]]\n",
      "\n",
      " [[24. 27.]\n",
      "  [21. 27.]\n",
      "  [19. 26.]\n",
      "  [19. 27.]\n",
      "  [21. 24.]\n",
      "  [21. 22.]\n",
      "  [20. 22.]\n",
      "  [20. 28.]\n",
      "  [23. 26.]]\n",
      "\n",
      " [[22. 25.]\n",
      "  [21. 26.]\n",
      "  [25. 27.]\n",
      "  [20. 24.]\n",
      "  [21. 27.]\n",
      "  [21. 23.]\n",
      "  [25. 28.]\n",
      "  [26. 28.]\n",
      "  [22. 27.]]\n",
      "\n",
      " [[21. 25.]\n",
      "  [25. 27.]\n",
      "  [22. 27.]\n",
      "  [24. 29.]\n",
      "  [29. 30.]\n",
      "  [26. 30.]\n",
      "  [21. 23.]\n",
      "  [22. 25.]\n",
      "  [23. 29.]]\n",
      "\n",
      " [[23. 24.]\n",
      "  [25. 31.]\n",
      "  [24. 26.]\n",
      "  [29. 31.]\n",
      "  [24. 25.]\n",
      "  [23. 25.]\n",
      "  [24. 28.]\n",
      "  [22. 29.]\n",
      "  [22. 23.]]\n",
      "\n",
      " [[23. 27.]\n",
      "  [28. 31.]\n",
      "  [26. 29.]\n",
      "  [24. 25.]\n",
      "  [28. 30.]\n",
      "  [26. 27.]\n",
      "  [25. 29.]\n",
      "  [25. 27.]\n",
      "  [32. 26.]]\n",
      "\n",
      " [[32. 33.]\n",
      "  [25. 26.]\n",
      "  [33. 26.]\n",
      "  [33. 25.]\n",
      "  [24. 31.]\n",
      "  [28. 30.]\n",
      "  [32. 30.]\n",
      "  [25. 29.]\n",
      "  [24. 25.]]\n",
      "\n",
      " [[33. 34.]\n",
      "  [32. 27.]\n",
      "  [26. 30.]\n",
      "  [25. 30.]\n",
      "  [26. 29.]\n",
      "  [34. 25.]\n",
      "  [34. 28.]\n",
      "  [33. 31.]\n",
      "  [32. 25.]]\n",
      "\n",
      " [[27. 31.]\n",
      "  [35. 30.]\n",
      "  [26. 27.]\n",
      "  [26. 31.]\n",
      "  [34. 28.]\n",
      "  [27. 28.]\n",
      "  [35. 28.]\n",
      "  [32. 27.]\n",
      "  [33. 31.]]\n",
      "\n",
      " [[34. 30.]\n",
      "  [27. 30.]\n",
      "  [29. 31.]\n",
      "  [32. 36.]\n",
      "  [34. 35.]\n",
      "  [32. 29.]\n",
      "  [32. 33.]\n",
      "  [35. 31.]\n",
      "  [32. 28.]]\n",
      "\n",
      " [[37. 31.]\n",
      "  [35. 31.]\n",
      "  [33. 34.]\n",
      "  [29. 31.]\n",
      "  [32. 31.]\n",
      "  [32. 29.]\n",
      "  [32. 34.]\n",
      "  [28. 31.]\n",
      "  [35. 36.]]\n",
      "\n",
      " [[32. 33.]\n",
      "  [33. 36.]\n",
      "  [35. 30.]\n",
      "  [33. 35.]\n",
      "  [33. 29.]\n",
      "  [32. 38.]\n",
      "  [38. 31.]\n",
      "  [38. 29.]\n",
      "  [37. 38.]]\n",
      "\n",
      " [[33. 34.]\n",
      "  [33. 35.]\n",
      "  [33. 30.]\n",
      "  [36. 30.]\n",
      "  [35. 36.]\n",
      "  [32. 31.]\n",
      "  [34. 37.]\n",
      "  [33. 31.]\n",
      "  [35. 30.]]\n",
      "\n",
      " [[33. 40.]\n",
      "  [39. 31.]\n",
      "  [37. 31.]\n",
      "  [36. 37.]\n",
      "  [36. 39.]\n",
      "  [33. 36.]\n",
      "  [32. 39.]\n",
      "  [32. 36.]\n",
      "  [33. 31.]]\n",
      "\n",
      " [[34. 39.]\n",
      "  [32. 40.]\n",
      "  [33. 38.]\n",
      "  [36. 39.]\n",
      "  [35. 40.]\n",
      "  [36. 37.]\n",
      "  [36. 38.]\n",
      "  [34. 36.]\n",
      "  [33. 37.]]\n",
      "\n",
      " [[40. 42.]\n",
      "  [39. 40.]\n",
      "  [37. 38.]\n",
      "  [34. 42.]\n",
      "  [36. 40.]\n",
      "  [35. 39.]\n",
      "  [39. 42.]\n",
      "  [34. 35.]\n",
      "  [35. 37.]]\n",
      "\n",
      " [[36. 39.]\n",
      "  [37. 39.]\n",
      "  [40. 41.]\n",
      "  [38. 40.]\n",
      "  [36. 41.]\n",
      "  [37. 42.]\n",
      "  [38. 41.]\n",
      "  [34. 35.]\n",
      "  [39. 40.]]\n",
      "\n",
      " [[39. 40.]\n",
      "  [43. 44.]\n",
      "  [35. 39.]\n",
      "  [36. 43.]\n",
      "  [38. 40.]\n",
      "  [37. 44.]\n",
      "  [38. 41.]\n",
      "  [42. 44.]\n",
      "  [40. 41.]]\n",
      "\n",
      " [[38. 40.]\n",
      "  [41. 45.]\n",
      "  [38. 44.]\n",
      "  [43. 44.]\n",
      "  [37. 43.]\n",
      "  [43. 45.]\n",
      "  [36. 37.]\n",
      "  [40. 43.]\n",
      "  [36. 44.]]\n",
      "\n",
      " [[39. 42.]\n",
      "  [37. 43.]\n",
      "  [37. 45.]\n",
      "  [37. 44.]\n",
      "  [42. 45.]\n",
      "  [38. 46.]\n",
      "  [42. 44.]\n",
      "  [39. 40.]\n",
      "  [38. 41.]]\n",
      "\n",
      " [[45. 46.]\n",
      "  [38. 45.]\n",
      "  [41. 44.]\n",
      "  [39. 42.]\n",
      "  [39. 44.]\n",
      "  [43. 46.]\n",
      "  [44. 47.]\n",
      "  [39. 41.]\n",
      "  [42. 44.]]\n",
      "\n",
      " [[45. 46.]\n",
      "  [39. 46.]\n",
      "  [43. 46.]\n",
      "  [47. 48.]\n",
      "  [46. 48.]\n",
      "  [42. 48.]\n",
      "  [41. 47.]\n",
      "  [41. 44.]\n",
      "  [45. 48.]]\n",
      "\n",
      " [[43. 46.]\n",
      "  [46. 47.]\n",
      "  [42. 47.]\n",
      "  [47. 48.]\n",
      "  [41. 43.]\n",
      "  [40. 43.]\n",
      "  [46. 48.]\n",
      "  [40. 45.]\n",
      "  [41. 49.]]\n",
      "\n",
      " [[42. 48.]\n",
      "  [41. 45.]\n",
      "  [47. 50.]\n",
      "  [42. 49.]\n",
      "  [43. 48.]\n",
      "  [44. 47.]\n",
      "  [41. 50.]\n",
      "  [42. 46.]\n",
      "  [41. 44.]]\n",
      "\n",
      " [[47. 51.]\n",
      "  [48. 49.]\n",
      "  [49. 51.]\n",
      "  [46. 49.]\n",
      "  [44. 51.]\n",
      "  [43. 45.]\n",
      "  [42. 49.]\n",
      "  [48. 50.]\n",
      "  [49. 50.]]\n",
      "\n",
      " [[47. 48.]\n",
      "  [44. 50.]\n",
      "  [51. 52.]\n",
      "  [46. 50.]\n",
      "  [48. 49.]\n",
      "  [49. 51.]\n",
      "  [44. 48.]\n",
      "  [43. 48.]\n",
      "  [43. 50.]]\n",
      "\n",
      " [[44. 45.]\n",
      "  [48. 51.]\n",
      "  [47. 48.]\n",
      "  [45. 50.]\n",
      "  [48. 53.]\n",
      "  [44. 47.]\n",
      "  [45. 52.]\n",
      "  [51. 52.]\n",
      "  [47. 50.]]\n",
      "\n",
      " [[47. 54.]\n",
      "  [50. 53.]\n",
      "  [48. 50.]\n",
      "  [50. 51.]\n",
      "  [48. 53.]\n",
      "  [49. 50.]\n",
      "  [45. 53.]\n",
      "  [46. 48.]\n",
      "  [48. 52.]]\n",
      "\n",
      " [[46. 55.]\n",
      "  [49. 55.]\n",
      "  [52. 53.]\n",
      "  [47. 51.]\n",
      "  [47. 55.]\n",
      "  [46. 51.]\n",
      "  [50. 51.]\n",
      "  [47. 52.]\n",
      "  [48. 54.]]\n",
      "\n",
      " [[49. 52.]\n",
      "  [50. 56.]\n",
      "  [53. 56.]\n",
      "  [50. 53.]\n",
      "  [52. 54.]\n",
      "  [47. 50.]\n",
      "  [48. 56.]\n",
      "  [48. 51.]\n",
      "  [47. 52.]]\n",
      "\n",
      " [[49. 51.]\n",
      "  [54. 55.]\n",
      "  [55. 56.]\n",
      "  [49. 56.]\n",
      "  [51. 52.]\n",
      "  [55. 57.]\n",
      "  [54. 56.]\n",
      "  [49. 50.]\n",
      "  [48. 55.]]\n",
      "\n",
      " [[49. 57.]\n",
      "  [50. 55.]\n",
      "  [53. 56.]\n",
      "  [50. 53.]\n",
      "  [52. 54.]\n",
      "  [55. 57.]\n",
      "  [54. 58.]\n",
      "  [49. 53.]\n",
      "  [51. 57.]]]\n"
     ]
    }
   ],
   "source": [
    "print(positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs_reshaped = positive_pairs.reshape((50 * 9), 2)\n",
    "negative_pairs_reshaped = negative_pairs.reshape((50 * 9), 2)\n",
    "person = person.reshape((450, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(positive_pairs)):\n",
    "# #     j will be from 0 to 50\n",
    "#     positive_list = []\n",
    "#     negative_list = []\n",
    "#     for k in range(len(positive_pairs)):\n",
    "        \n",
    "#         pos_index1  =  positive_pairs[k][0]\n",
    "#         pos_index2  =  positive_pairs[k][1]\n",
    "#         print(pos_index2)\n",
    "#         neg_index1  =  negative_pairs[k][0]\n",
    "#         neg_index2  =  negative_pairs[k][1]\n",
    "        \n",
    "#         pos_pair = (train_data[pos_index1, :], train_data[pos_index2, :], math.floor(pos_index1 / 50))\n",
    "#         neg_pair = (train_data[neg_index1, :], train_data[neg_index2, :], math.floor(pos_index1 / 50))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
    "\n",
    "\n",
    "# class LSTM(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "#         self.linear = nn.Linear(hidden_size, 513)\n",
    "#         self.act = torch.sigmoid\n",
    "      \n",
    "#     def forward(self, data):\n",
    "#         res = []\n",
    "#         for i in range(2): # Siamese nets; sharing weights\n",
    "#             x = data[i]\n",
    "#             print('data')\n",
    "#             print(self.rnn)\n",
    "#             pred, hidden = self.rnn(x[0])\n",
    "#             pred = self.act(self.linear(pred)).view(pred.data.shape[0], BATCH, 513)\n",
    "#             res.append(pred)\n",
    "         \n",
    "#         res = torch.abs(res[1] - res[0])\n",
    "#         res = self.linear2(res)\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_pair_loader = torch.utils.data.DataLoader(positive_pairs_reshaped, batch_size=1)\n",
    "train_negative_pair_loader = torch.utils.data.DataLoader(negative_pairs_reshaped, batch_size=1)\n",
    "train_label_loader = torch.utils.data.DataLoader(person, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hackernoon.com/one-shot-learning-with-siamese-networks-in-pytorch-8ddaab10340e\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1372, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6000e-11, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-afb2aaf1191a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0membed_anchor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                     \u001b[0membed_a\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_anchor\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0membed_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-afb2aaf1191a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         for i in range(3): # Siamese nets; sharing weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://hackernoon.com/one-shot-learning-with-siamese-networks-in-pytorch-8ddaab10340e\n",
    "# ref: https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, 1)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        \n",
    "        self.act = F.relu\n",
    "        \n",
    "    def forward(self, data):\n",
    "#         pred, hidden = self.rnn(x, None)\n",
    "#         pred = self.act(self.linear(pred)).view(pred.data.shape[0], BATCH, 513)\n",
    "#         res = []\n",
    "#         for i in range(3): # Siamese nets; sharing weights\n",
    "        x = torch.tensor(data).cuda()\n",
    "        pred, hidden = self.rnn(x[np.newaxis, :, :])\n",
    "        pred = pred.view(pred.shape[0], -1)\n",
    "        pred = self.act(self.linear1(pred))\n",
    "        pred = self.linear2(pred)\n",
    "        return pred\n",
    "#         print(res[0], res[1])\n",
    "#         res = torch.dot(torch.squeeze(res[1]), torch.squeeze(res[0]))\n",
    "#         res = F.sigmoid(res)\n",
    "#         return res\n",
    "\n",
    "neural_network = LSTM(513,2)\n",
    "neural_network = neural_network.cuda()\n",
    "# loss_function= nn.TripletMarginLoss()\n",
    "loss_function= ContrastiveLoss()\n",
    "para = neural_network.parameters()\n",
    "optimizer = torch.optim.Adam(params=para, lr=0.00001)\n",
    "loss_list = []\n",
    "epochs = 100\n",
    "# count = 0\n",
    "for i in range(epochs):\n",
    "    positive_pairs = iter(train_positive_pair_loader)\n",
    "    negative_pairs = iter(train_negative_pair_loader)\n",
    "    labels = iter(train_label_loader)\n",
    "    while True:\n",
    "        try:\n",
    "#             count = count + 1\n",
    "            positive_sets = positive_pairs.next()[0]\n",
    "            negative_sets = negative_pairs.next()[0]\n",
    "\n",
    "            target = labels.next()[0]\n",
    "#             print(target)\n",
    "            anchor = training[int(positive_sets[0].numpy())]\n",
    "            a = training[int(positive_sets[1].numpy())]\n",
    "            b = training[int(negative_sets[1].numpy())]\n",
    "#             positive_tensors = [training[int(positive_sets[0].numpy())],training[int(positive_sets[1].numpy())]]\n",
    "#             negative_tensors = [training[int(positive_sets[0].numpy())],training[int(negative_sets[1].numpy())]]\n",
    "#             print(positive_tensors[0].shape)\n",
    "            optimizer.zero_grad()\n",
    "            for i in range(2):\n",
    "                if i == 0:\n",
    "                    embed_anchor = neural_network(anchor)\n",
    "                    embed_a  = neural_network(a)\n",
    "                    loss = loss_function(embed_anchor ,embed_a, 1 )\n",
    "                else:\n",
    "                    embed_anchor = neural_network(anchor)\n",
    "                    embed_b  = neural_network(b)\n",
    "                    loss = loss_function(embed_anchor ,embed_b, 0 )\n",
    "#             embed_anchor = neural_network(anchor)\n",
    "#             embed_a  = neural_network(a)\n",
    "#             embed_b  = neural_network(b)\n",
    "            \n",
    "#             negative_set_output  = neural_network(negative_tensors)\n",
    "#             print(positive_set_output)\n",
    "#             print(negative_set_output)\n",
    "#             loss = loss_function(embed_anchor ,embed_a, embed_b )\n",
    "#             loss_positive = F.cross_entropy(positive_set_output , torch.tensor(1).type(torch.LongTensor).cuda())\n",
    "#             loss_negative = F.cross_entropy(negative_set_output , torch.tensor(0).type(torch.LongTensor).cuda())\n",
    "#             print('positive loass')\n",
    "#             print(loss_positive)\n",
    "#             print('negative loss')\n",
    "#             print(loss_negative)\n",
    "#             loss = loss_positive + loss_negative\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except StopIteration:\n",
    "            break\n",
    "    print(loss)\n",
    "    loss_list.append(loss.data.cpu().numpy())\n",
    "print(loss.data)\n",
    "plt.plot(range(epochs), loss_list)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs, negative_pairs, person = get_pairs(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs_reshaped = positive_pairs.reshape((20 * 9), 2)\n",
    "negative_pairs_reshaped = negative_pairs.reshape((20 * 9), 2)\n",
    "person = person.reshape((180, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive_pair_loader = torch.utils.data.DataLoader(positive_pairs_reshaped, batch_size=1)\n",
    "test_negative_pair_loader = torch.utils.data.DataLoader(negative_pairs_reshaped, batch_size=1)\n",
    "test_label_loader = torch.utils.data.DataLoader(person, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_negative_pair_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    positive_pairs = iter(test_positive_pair_loader)\n",
    "    negative_pairs = iter(test_negative_pair_loader)\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    dist1 = np.zeros(180)\n",
    "    dist2 = np.zeros(180)\n",
    "    i = 0\n",
    "#     labels = iter(train_label_loader)\n",
    "    while True:\n",
    "        try:\n",
    "#             count = count + 1\n",
    "            positive_sets = positive_pairs.next()[0]\n",
    "            negative_sets = negative_pairs.next()[0]\n",
    "            \n",
    "#             target = labels.next()[0]\n",
    "#             print(target)\n",
    "            anchor = training[int(positive_sets[0].numpy())]\n",
    "            a = training[int(positive_sets[1].numpy())]\n",
    "            b = training[int(negative_sets[1].numpy())]\n",
    "#             print(positive_sets[0],positive_sets[1])\n",
    "#             print(positive_sets[0], negative_sets[1])\n",
    "#             positive_tensors = [training[int(positive_sets[0].numpy())],training[int(positive_sets[1].numpy())]]\n",
    "#             negative_tensors = [training[int(positive_sets[0].numpy())],training[int(negative_sets[1].numpy())]]\n",
    "#             print(positive_tensors[0].shape)\n",
    "\n",
    "#             embed_anchor = neural_network(anchor)\n",
    "#             embed_a  = neural_network(a)\n",
    "#             embed_b  = neural_network(b)\n",
    "            \n",
    "            output1 = neural_network(anchor)\n",
    "            output2 = neural_network(a)\n",
    "            output3 = neural_network(b)\n",
    "            euclidean_distance1 = F.pairwise_distance(torch.tensor(output1), torch.tensor(output2))\n",
    "            euclidean_distance2 = F.pairwise_distance(torch.tensor(output1), torch.tensor(output3))\n",
    "            dist1[i] = euclidean_distance1\n",
    "            dist2[i] = euclidean_distance2\n",
    "            \n",
    "            i = i+1\n",
    "#             threshold = 0.31\n",
    "#             if euclidean_distance1 < threshold:\n",
    "#                 positive = positive + 1\n",
    "#             if euclidean_distance2 >= threshold:\n",
    "#                 negative = negative + 1\n",
    "#             print('dist1', euclidean_distance1)\n",
    "#             print('dist2', euclidean_distance2)\n",
    "        except StopIteration:\n",
    "            a = np.sum(dist2 - dist1)\n",
    "            print('metric' , a)\n",
    "            print(positive)\n",
    "            print(negative)\n",
    "            break \n",
    "            \n",
    "#             negative_set_output  = neural_network(negative_tensors)\n",
    "#             print(positive_set_output)\n",
    "#             print(negative_set_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0,1,2,3,4])\n",
    "y = x[0:3]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
