{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bu-AIG_D8wmM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZE2A1TJ9Yh5"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2nUQYKf952Z"
   },
   "outputs": [],
   "source": [
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PttlgK2t8wmP"
   },
   "outputs": [],
   "source": [
    "s, sr=librosa.load('data/train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load('data/train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQeyZ_968wmS"
   },
   "outputs": [],
   "source": [
    "s_abs = np.abs(S)\n",
    "x_abs = np.abs(X)\n",
    "s = torch.tensor(np.transpose(s_abs)).cuda()\n",
    "x = torch.tensor(np.transpose(x_abs)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LyMB9Fu18wmU",
    "outputId": "2656d3b7-d216-4adb-b526-3e64a92a26e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2459, 513])\n",
      "torch.Size([2459, 513])\n"
     ]
    }
   ],
   "source": [
    "print(s.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9KOJFI-8wmY"
   },
   "outputs": [],
   "source": [
    "BATCH = 128\n",
    "train_loader = torch.utils.data.DataLoader(x, batch_size=BATCH)\n",
    "test_loader = torch.utils.data.DataLoader(s, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "abH0JMoS8wmb",
    "outputId": "abd06abf-3e2d-4f12-92b1-ebca7e5e195a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 513])\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(train_loader)\n",
    "test_data = test_iter.next()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qfhXwM358wme",
    "outputId": "1cd3d4fe-466f-4140-f748-92e1d6efa40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 513])\n"
     ]
    }
   ],
   "source": [
    "my_data = test_data.squeeze().cuda()\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uIkXsyNkGkPu",
    "outputId": "5b2c72da-a2eb-4596-f0a2-8cfeae9e3e8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_shape(input, filter, padding, stride):\n",
    "  return (((input - filter + (2*padding)) / stride)) + 1\n",
    "\n",
    "get_shape(511, 2,2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR5OJ538wmh"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    \n",
    "    conv1_channel_in = 1\n",
    "    conv1_number_of_filter = 16\n",
    "    conv1_kernel_size = 2\n",
    "    conv1_stride = 1\n",
    "    conv1_padding = 0\n",
    "    \n",
    "    max_poo1_kernel_size  = 2\n",
    "    max_poo1_kernel_stride  = 1\n",
    "    \n",
    "    conv2_number_of_filter = 32\n",
    "    conv2_kernel_size = 2\n",
    "    conv2_stride = 1\n",
    "    conv2_padding = 2\n",
    "    \n",
    "    max_poo2_kernel_size  = 2\n",
    "    max_poo2_kernel_stride  = 1\n",
    "    \n",
    "   \n",
    "    conv3_number_of_filter = 64\n",
    "    conv3_kernel_size = 2\n",
    "    conv3_stride = 1\n",
    "    conv3_padding = 2\n",
    "    \n",
    "    max_poo3_kernel_size  = 2\n",
    "    max_poo3_kernel_stride  = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(conv1_channel_in, conv1_number_of_filter, kernel_size=conv1_kernel_size, stride=conv1_stride, padding=conv1_padding),\n",
    "            nn.ReLU(),       \n",
    "            nn.MaxPool2d(kernel_size=max_poo1_kernel_size, stride=max_poo1_kernel_stride))\n",
    "    \n",
    "    conv1_firstdim = get_shape(513, conv1_kernel_size, conv1_padding, conv1_stride)\n",
    "    conv1_seconddim = get_shape(20, conv1_kernel_size, conv1_padding, conv1_stride)\n",
    "    \n",
    "    print(\"convolution 1\")\n",
    "    print(\"x:\", conv1_firstdim)\n",
    "    print(\"y:\", conv1_seconddim)\n",
    "    \n",
    "    pool1_firstdim = get_shape(conv1_firstdim, max_poo1_kernel_size, 0, max_poo1_kernel_stride)\n",
    "    pool1_seconddim = get_shape(conv1_seconddim, max_poo1_kernel_size, 0, max_poo1_kernel_stride)\n",
    "    \n",
    "    print(\"pool 1\")\n",
    "    print(\"x:\", pool1_firstdim)\n",
    "    print(\"y:\", pool1_seconddim)\n",
    "    \n",
    "    self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(conv1_number_of_filter, conv2_number_of_filter, kernel_size=conv2_kernel_size, stride=conv2_stride,  padding=conv2_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=max_poo2_kernel_size, stride=max_poo2_kernel_stride))\n",
    "    \n",
    "    conv2_firstdim = get_shape(pool1_firstdim, conv2_kernel_size, conv2_padding, conv2_stride)\n",
    "    conv2_seconddim = get_shape(pool1_seconddim, conv2_kernel_size, conv2_padding, conv2_stride)\n",
    "    \n",
    "    print(\"convolution 2\")\n",
    "    print(\"x:\",  conv2_firstdim)\n",
    "    print(\"y:\", conv2_seconddim)\n",
    "    \n",
    "    pool2_firstdim = get_shape(conv2_firstdim, max_poo2_kernel_size, 0, max_poo2_kernel_stride)\n",
    "    pool2_seconddim = get_shape(conv2_seconddim, max_poo2_kernel_size,0,  max_poo2_kernel_stride)\n",
    "    \n",
    "    print(\"pool 2\")\n",
    "    print(\"x:\",  pool2_firstdim)\n",
    "    print(\"y:\", pool2_seconddim)\n",
    "    \n",
    "    self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(conv2_number_of_filter, conv3_number_of_filter, kernel_size=conv3_kernel_size, stride=conv3_stride,  padding=conv3_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=max_poo2_kernel_size, stride=max_poo2_kernel_stride))\n",
    "    \n",
    "    conv3_firstdim = get_shape(pool2_firstdim, conv3_kernel_size, conv3_padding,  conv3_stride)\n",
    "    conv3_seconddim = get_shape(pool2_seconddim, conv3_kernel_size, conv3_padding,  conv3_stride)\n",
    "    \n",
    "    print(\"convolution 3\")\n",
    "    print(\"x:\", conv3_firstdim)\n",
    "    print(\"y:\", conv3_seconddim)\n",
    "    \n",
    "    pool3_firstdim = get_shape(conv3_firstdim, max_poo3_kernel_size, 0, max_poo3_kernel_stride)\n",
    "    pool3_seconddim = get_shape(conv3_seconddim, max_poo3_kernel_size, 0,  max_poo3_kernel_stride)\n",
    "    \n",
    "    print(\"Pool 3\")\n",
    "    print(\"x:\", pool3_firstdim)\n",
    "    print(\"y:\", pool3_seconddim)\n",
    "    \n",
    "    final_out_dim = pool3_firstdim * pool3_seconddim * 64\n",
    "    print(final_out_dim)\n",
    "    self.fc1 = nn.Linear(in_features=int(final_out_dim), out_features=513)\n",
    "    \n",
    "  def forward(self, data):\n",
    "#     print(data.shape)\n",
    "    data = data[np.newaxis, np.newaxis,:, :]\n",
    "    output = self.conv1(data)\n",
    "#     print(data.shape)\n",
    "    output = self.conv2(output)\n",
    "#     print(output.shape)\n",
    "    output = self.conv3(output)\n",
    "    output = output.reshape(output.shape[0], -1)\n",
    "#     print(output.shape)\n",
    "    output = self.fc1(output)\n",
    "    final = torch.nn.functional.relu(output)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "v7EmSmf2HBUu",
    "outputId": "fcbb403a-a54c-4851-fc84-fc62548bd727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution 1\n",
      "x: 512.0\n",
      "y: 19.0\n",
      "pool 1\n",
      "x: 511.0\n",
      "y: 18.0\n",
      "convolution 2\n",
      "x: 514.0\n",
      "y: 21.0\n",
      "pool 2\n",
      "x: 513.0\n",
      "y: 20.0\n",
      "convolution 3\n",
      "x: 516.0\n",
      "y: 23.0\n",
      "Pool 3\n",
      "x: 515.0\n",
      "y: 22.0\n",
      "725120.0\n"
     ]
    }
   ],
   "source": [
    "neural_network = NeuralNetwork().cuda()\n",
    "# child_counter = 0\n",
    "# for child in neural_network.children():\n",
    "#   print(\" child\", child_counter, \"is:\")\n",
    "#   print(child)\n",
    "#   for param in child.parameters():\n",
    "#     print(param)\n",
    "#   child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1254
    },
    "colab_type": "code",
    "id": "ftzpTpkH8wmk",
    "outputId": "e02630eb-e7b2-470d-a898-7577c18319a0",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.39 GiB (GPU 0; 6.00 GiB total capacity; 4.17 GiB already allocated; 442.45 MiB free; 78.00 KiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b8ebd18c5d4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_output\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtarget_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'exp_avg'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                     \u001b[1;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'exp_avg_sq'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                         \u001b[1;31m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.39 GiB (GPU 0; 6.00 GiB total capacity; 4.17 GiB already allocated; 442.45 MiB free; 78.00 KiB cached)"
     ]
    }
   ],
   "source": [
    "# using Adam with learning rat .001 keeping everything else default.\n",
    "# neural_network = NeuralNetwork().cuda()\n",
    "loss_function= nn.MSELoss()\n",
    "para = neural_network.parameters()\n",
    "optimizer = torch.optim.Adam(params=para, lr=0.01)\n",
    "loss_list = []\n",
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    input_iter = iter(train_loader)\n",
    "    target_iter = iter(test_loader)\n",
    "    while True:\n",
    "        batch_count = 0 \n",
    "        try:\n",
    "            input_batch = input_iter.next()\n",
    "#             print(\"input batch shape\", input_batch.shape)\n",
    "            target_batch = target_iter.next()\n",
    "            batch_count = batch_count + 1\n",
    "#             print(\"batch\", str(batch_count))\n",
    "            for j in range(input_batch.shape[0] - 20):\n",
    "#                 print(j)\n",
    "                input_set = input_batch[j:j+20,:].cuda()\n",
    "                target_set = target_batch[j:j+20,:].cuda()\n",
    "                network_output  = neural_network(input_set)\n",
    "                loss = loss_function(network_output , target_set)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                print(i)\n",
    "        except StopIteration:\n",
    "            break\n",
    "    loss_list.append(loss.data.cpu().numpy())\n",
    "# loss_list.append(loss.data.cpu().numpy())\n",
    "print(loss.data)\n",
    "plt.plot(range(epochs), loss_list)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsCtFjE68wmn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGO3Mn1d8wmp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2_part2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
