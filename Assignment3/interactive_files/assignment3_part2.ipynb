{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukwBGL43t-jf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Sf20tXcHuCum",
    "outputId": "d35d05b4-971f-4fe6-837d-6f8ef828b93a"
   },
   "outputs": [],
   "source": [
    "# code used to run on COLAB\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# os.chdir('/content/drive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NAsB5B8t-jj"
   },
   "outputs": [],
   "source": [
    "training_folder = 'tr'\n",
    "validation_folder = 'v'\n",
    "test_folder = 'te'\n",
    "file_extension = '.wav'\n",
    "# Paths for varios files\n",
    "train_dirty_file_path = 'numpy_files/file_names/train/train_dirty_files.npy'\n",
    "train_speech_file_path = 'numpy_files/file_names/train/train_speech_files.npy'\n",
    "train_noise_file_path = 'numpy_files/file_names/train/train_noise_files.npy'\n",
    "\n",
    "train_librosa_n_list_path = 'numpy_files/librosa_data/train/train_n_list.npy'\n",
    "train_librosa_s_list_path = 'numpy_files/librosa_data/train/train_s_list.npy'\n",
    "train_librosa_x_list_path = 'numpy_files/librosa_data/train/train_x_list.npy'\n",
    "\n",
    "train_librosa_complex_list_path = 'numpy_files/librosa_data/train/train_complex_list.npy'\n",
    "\n",
    "test_dirty_file_path = 'numpy_files/file_names/test/test_dirty_files.npy'\n",
    "test_librosa_x_list_path = 'numpy_files/librosa_data/test/test_x_list.npy'\n",
    "test_librosa_complex_list_path = 'numpy_files/librosa_data/test/test_complex_list.npy'\n",
    "\n",
    "ibm_path = 'numpy_files/ibm.npy'\n",
    "dimension = 513\n",
    "# number of files you want to denoise\n",
    "file_count_to_denoise = 1200\n",
    "# if this value is try it will load files from 'npy' file, the path are given above\n",
    "load_existing_files = True\n",
    "# number of files you want to test\n",
    "test_files_count = 400 \n",
    "epochs = 200\n",
    "sample_rate = 16000\n",
    "# if you want to save the files and overwrite existing files on the path given\n",
    "save_files = False\n",
    "\n",
    "padding_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tiv77UApt-jn"
   },
   "outputs": [],
   "source": [
    "# function to generate the file numbers\n",
    "def get_file_number(number):\n",
    "    return \"0\" * (4 - len(number)) + number + file_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNxhKkhPt-jq"
   },
   "outputs": [],
   "source": [
    "# function to generate the file names\n",
    "def get_files(folder, test=False):\n",
    "    dirty_files = []\n",
    "    speech_files = []\n",
    "    noise_files = []\n",
    "    for i in range(file_count_to_denoise):\n",
    "        dirty_files.append(folder+'/' + folder + 'x'  + get_file_number(str(i)))\n",
    "        speech_files.append(folder+'/' + folder +'s' + get_file_number(str(i)))\n",
    "        noise_files.append(folder+ '/' + folder + 'n' + get_file_number(str(i)))\n",
    "\n",
    "    return np.array(dirty_files), np.array(speech_files), np.array(noise_files)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_test(folder):\n",
    "    dirty_files = []\n",
    "    for i in range(test_files_count):\n",
    "        dirty_files.append(folder+'/' + folder + 'x'  + get_file_number(str(i)))\n",
    "    return np.array(dirty_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UXBAVKj-t-ju",
    "outputId": "3edd271e-6918-475c-cbae-ec1cbc67ea6b"
   },
   "outputs": [],
   "source": [
    "if load_existing_files:\n",
    "    print('loading existing files')\n",
    "    train_dirty_files = torch.load(train_dirty_file_path)\n",
    "    train_speech_files = torch.load(train_speech_file_path)\n",
    "    train_noise_files = torch.load(train_noise_file_path)\n",
    "else:\n",
    "    train_dirty_files, train_speech_files, train_noise_files = get_files(training_folder)\n",
    "\n",
    "train_dirty_files = train_dirty_files[:file_count_to_denoise].reshape(file_count_to_denoise, 1)\n",
    "train_speech_files = train_speech_files[:file_count_to_denoise].reshape(file_count_to_denoise,1)\n",
    "train_noise_files = train_noise_files[:file_count_to_denoise].reshape(file_count_to_denoise,1)\n",
    "  \n",
    "if save_files:\n",
    "    torch.save(train_dirty_files, train_dirty_file_path)\n",
    "    torch.save(train_speech_files, train_speech_file_path)\n",
    "    torch.save(train_noise_files, train_noise_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zVyPzJNN7Tbl",
    "outputId": "4f0742a0-8920-4db3-dc1e-b932ec282548"
   },
   "outputs": [],
   "source": [
    "print(train_dirty_files.shape)\n",
    "print(train_speech_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUSw-XFot-j1"
   },
   "outputs": [],
   "source": [
    "def get_processed_lists(dirty_files, speech_files, noise_files, test=False):\n",
    "    x_list = np.zeros(shape=(1,513, 200))\n",
    "    x_complex = []\n",
    "    s_list = np.zeros(shape=(1,513, 200))\n",
    "    n_list = np.zeros(shape=(1,513, 200))\n",
    "    for i in range(file_count_to_denoise):\n",
    "        print(\"Running for tile\", str(i))\n",
    "        #     for dirty files\n",
    "        x, srx=librosa.load(dirty_files[i][0], sr=None)\n",
    "        X=librosa.stft(x, n_fft=1024, hop_length=512)\n",
    "        #     for speech files\n",
    "\n",
    "        s, srs=librosa.load(speech_files[i][0], sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        #     for noise files\n",
    "        n, srn=librosa.load(noise_files[i][0], sr=None)\n",
    "        N=librosa.stft(n, n_fft=1024, hop_length=512)\n",
    "\n",
    "        print(x.shape)\n",
    "        x_abs = np.abs(X)\n",
    "        s_abs = np.abs(S)\n",
    "        n_abs = np.abs(N)\n",
    "\n",
    "        x_zeros_to_pad = padding_length - X.shape[1]\n",
    "        s_zeros_to_pad = padding_length - S.shape[1]\n",
    "        n_zeros_to_pad = padding_length - N.shape[1]\n",
    "\n",
    "        x_abs = np.pad(x_abs,((0,0), (0, x_zeros_to_pad)), 'constant') \n",
    "        s_abs = np.pad(s_abs, ((0,0), (0, s_zeros_to_pad)), 'constant') \n",
    "        n_abs = np.pad(n_abs, ((0,0), (0, n_zeros_to_pad)), 'constant') \n",
    "\n",
    "        reshaped_x_abs = x_abs.reshape(1 , dimension, padding_length)\n",
    "        reshaped_s_abs = s_abs.reshape(1 , dimension, padding_length)\n",
    "        reshaped_n_abs = n_abs.reshape(1 , dimension, padding_length)\n",
    "\n",
    "        x_complex.append(X)\n",
    "        if i == 0:\n",
    "            x_list[0] = reshaped_x_abs\n",
    "            s_list[0] = reshaped_s_abs\n",
    "            n_list[0] = reshaped_n_abs\n",
    "        else:\n",
    "            x_list = np.append(x_list, reshaped_x_abs, axis = 0)\n",
    "            s_list = np.append(s_list, reshaped_s_abs, axis = 0)\n",
    "            n_list = np.append(n_list,reshaped_n_abs, axis = 0)\n",
    "    return s_list,n_list,x_list, x_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CV7x33tEo737"
   },
   "outputs": [],
   "source": [
    "def get_processed_list_test(dirty_files):\n",
    "    x_list = []\n",
    "    x_complex = []\n",
    "\n",
    "    for i in range(test_files_count):\n",
    "        print(\"Running for tile\", str(i))\n",
    "        #     for dirty files\n",
    "        x, srx=librosa.load(dirty_files[i][0], sr=None)\n",
    "        X=librosa.stft(x, n_fft=1024, hop_length=512)\n",
    "\n",
    "\n",
    "        x_abs = np.abs(X)\n",
    "\n",
    "        x_list.append(x_abs)\n",
    "        x_complex.append(X)\n",
    "\n",
    "    return x_list, x_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkePBJCJjV21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if load_existing_files:\n",
    "    train_s_list = torch.load(train_librosa_s_list_path)\n",
    "    train_n_list = torch.load(train_librosa_n_list_path)\n",
    "    train_x_list = torch.load(train_librosa_x_list_path)\n",
    "    train_x_complex = torch.load(train_librosa_complex_list_path)\n",
    "else:\n",
    "    train_s_list, train_n_list, train_x_list, train_x_complex = get_processed_lists(train_dirty_files, train_speech_files, train_noise_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uB5npDwo74K"
   },
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    torch.save(train_s_list, train_librosa_s_list_path)\n",
    "    torch.save(train_n_list , train_librosa_n_list_path)\n",
    "    torch.save(train_x_list , train_librosa_x_list_path)\n",
    "    torch.save(train_x_complex, train_librosa_complex_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm = 1 * ( train_s_list > train_n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(ibm))\n",
    "print(np.min(ibm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 1\n",
    "train_loader = torch.utils.data.DataLoader(train_x_list, batch_size=BATCH)\n",
    "test_loader = torch.utils.data.DataLoader(ibm, batch_size=BATCH)\n",
    "# test_loader = torch.utils.data.DataLoader(train_s_list, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "3rqxA59G7YE2",
    "outputId": "3fd034d9-17e0-421d-e4b9-9e57e63fb0b4"
   },
   "outputs": [],
   "source": [
    "#Ref : https://nipunbatra.github.io/blog/2018/denoising.html\n",
    "#Ref: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, 513)\n",
    "        self.act = torch.sigmoid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.act(self.linear(pred)).view(pred.data.shape[0], BATCH, 513)\n",
    "        \n",
    "        return pred\n",
    "model = LSTM(513, 256).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2939
    },
    "colab_type": "code",
    "id": "q8jJdrTx_aQa",
    "outputId": "5ded1ead-16e9-4b58-d3aa-26663df32050",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_function= nn.MSELoss()\n",
    "para = model.parameters()\n",
    "optimizer = torch.optim.Adam(params=para, lr=0.001)\n",
    "loss_list = []\n",
    "for i in range(epochs):\n",
    "    total_loss = 0\n",
    "    print(\"Epoc\", i)\n",
    "    input_iter = iter(train_loader)\n",
    "    target_iter = iter(test_loader)\n",
    "    file_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            file_count += 1\n",
    "        \n",
    "            input_set = input_iter.next()\n",
    "            target_set = target_iter.next()\n",
    "            input_set  = Variable(input_set.reshape(padding_length, BATCH, dimension))\n",
    "            target_set = Variable(target_set.reshape(padding_length, BATCH, dimension))\n",
    "    \n",
    "            input_set = input_set.to(dtype=torch.float)\n",
    "            target_set = target_set.to(dtype=torch.float)\n",
    "            input_set = input_set.cuda()\n",
    "            target_set = target_set.cuda()\n",
    "\n",
    "    \n",
    "            network_output  = model(input_set)\n",
    "            loss = loss_function(network_output , target_set)\n",
    "            total_loss += loss.data.cpu().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "        except StopIteration:\n",
    "            print(\"break\")\n",
    "            break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4F5ZTmll3hn"
   },
   "outputs": [],
   "source": [
    "# validation_dirty_files, validation_speech_files, validation_noise_files = get_files(validation_folder)\n",
    "if load_existing_files:\n",
    "    test_dirty_files = torch.load(test_dirty_file_path)\n",
    "else:\n",
    "    test_dirty_files = get_files_test(test_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pY0hwymQo75t"
   },
   "outputs": [],
   "source": [
    "test_dirty_files = test_dirty_files.reshape(test_dirty_files.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dirty_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8UftuOJQo75z",
    "outputId": "83e654ba-94ee-476c-819a-7aedf386d361"
   },
   "outputs": [],
   "source": [
    "print(test_dirty_files.shape)\n",
    "if save_files:\n",
    "    torch.save(test_dirty_files, test_dirty_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ctVGKRU_o752",
    "outputId": "af8c5a59-50ef-41e2-c455-b6cfbee533a2"
   },
   "outputs": [],
   "source": [
    "test_dirty_files.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEReVxr3nILP"
   },
   "source": [
    "**--------------------------------------------------------------------------------------------------Testing Begins-----------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eFFkjf-ul_aQ",
    "outputId": "d1c92bb1-1062-49f7-d713-e616b8d311b3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if load_existing_files:\n",
    "    test_x_list = torch.load(test_librosa_x_list_path)\n",
    "    test_x_complex = torch.load(test_librosa_complex_list_path)\n",
    "else:\n",
    "    test_x_list, test_x_complex = get_processed_list_test(test_dirty_files)\n",
    "x_list = test_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "16J-HnTeo76A",
    "outputId": "d0fc746d-db7d-49f4-c5e9-cb9177eaef15"
   },
   "outputs": [],
   "source": [
    "len(test_x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6pKyqwEo76Z"
   },
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    torch.save(test_x_list,test_librosa_x_list_path)\n",
    "    torch.save(test_x_complex, test_librosa_complex_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-052YZIso76e",
    "outputId": "803b216a-8ddd-41c2-cef4-f6cbb3a8af3a"
   },
   "outputs": [],
   "source": [
    "x_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2i8pP3Kfo76v",
    "outputId": "7f52bfcc-07ce-41f8-f1db-59c004a50a79"
   },
   "outputs": [],
   "source": [
    "x_list[0].reshape(x_list[0].shape[0],x_list[0].shape[1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nn5BX_a9l2Gp",
    "outputId": "ea438035-84cc-4aac-e447-34ed726a1c45"
   },
   "outputs": [],
   "source": [
    "output_istft = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(x_list)):\n",
    "        model_input = Variable(torch.Tensor(x_list[i].reshape(-1, BATCH, dimension))).cuda()\n",
    "        prediction = model(model_input)\n",
    "        m = prediction.cpu().numpy()\n",
    "        m = 1 * (m >= 0.5)\n",
    "        complex_x = test_x_complex[i] \n",
    "        m = m.reshape(m.shape[2], m.shape[0])\n",
    "        result = np.multiply(complex_x , m)\n",
    "        result_istft = librosa.istft(result, hop_length=512)\n",
    "        output_istft.append(result_istft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAwR4O704CR0"
   },
   "outputs": [],
   "source": [
    "\n",
    "librosa.output.write_wav('test_result.wav', output_istft[3], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "0TwNesbyDrmh",
    "outputId": "41c5859f-860f-4c66-bdb1-bcf41166d5f1"
   },
   "outputs": [],
   "source": [
    "ipd.Audio('test_result.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLv7c7acB7iy"
   },
   "outputs": [],
   "source": [
    "for i in range(len(output_istft)):\n",
    "    librosa.output.write_wav('test'+ str(i) + '.wav', output_istft[i], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQ2XrngztpGU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNg-S5nD2Zo5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_part2_local.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
